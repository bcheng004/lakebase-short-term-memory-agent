{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e411b194-dd96-4131-ab8a-5b8ba9914df9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq mlflow langchain langgraph==0.3.4 databricks-langchain databricks-agents unitycatalog-langchain[databricks] uv langgraph-checkpoint-postgres==2.0.21 psycopg[binary,pool]\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0550d280-c496-4a2e-9bdc-814a428dee43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43ec4cb9-6706-473c-8cce-ad05defa9f63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Mosaic AI Agent Framework: Author and deploy a Stateful Agent using Databricks Lakebase and LangGraph\n",
    "This notebook demonstrates how to build a stateful agent using the Mosaic AI Agent Framework and LangGraph, with Lakebase as the agent’s durable memory and checkpoint store. In this notebook, you will:\n",
    "1. Author a Stateful Agent graph with LakeBase (the new Postgres database in Databricks) and Langgraph to manage state using thread ids in a Databricks Agent \n",
    "2. Wrap the LangGraph agent with MLflow ChatAgent to ensure compatibility with Databricks features\n",
    "3. Test the agent's behavior locally\n",
    "4. Register model to Unity Catalog, log and deploy the agent for use in apps and Playground\n",
    "\n",
    "We use [PostgresSaver in Langgraph](https://api.python.langchain.com/en/latest/checkpoint/langchain_postgres.checkpoint.PostgresSaver.html) to open a connection with our Lakebase, pass it into the checkpoint and pass that into the LangGraph Agent\n",
    "\n",
    "## Why use Lakebase?\n",
    "Stateful agents need a place to persist, resume, and inspect their work. Lakebase provides a managed, UC-governed store for agent state:\n",
    "- Durable, resumable state. Automatically capture threads, intermediate checkpoints, tool outputs, and node state after each graph step—so you can resume, branch, or replay any point in time.\n",
    "- Queryable & observable. Because state lands in the Lakehouse, you can use SQL (or notebooks) to audit conversations and build upon other Databricks functionality like dashboards\n",
    "- Governed by Unity Catalog. Apply data permissions, lineage, and auditing to AI state, just like any other table.\n",
    "\n",
    "## What are Stateful Agents?\n",
    "Unlike stateless LLM calls, a stateful agent keeps and reuses context across steps and sessions. Each new conversation is tracked with a thread ID, which represents the logical task or dialogue stream. This way, you can pick up an existing thread and continue the conversation with your Agent.\n",
    "\n",
    "## Prerequisites\n",
    "- Create a Lakebase instance, see Databricks documentation ([AWS](https://docs.databricks.com/aws/en/oltp/create/) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/oltp/create/)). \n",
    "- You can create a Lakebase instance by going to SQL Warehouses -> Lakebase Postgres -> Create database instance. You will need to retrieve values from the \"Connection details\" section of your Lakebase to fill out this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb3511ac-953a-4707-bea3-be4376f4ed42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(name=\"catalog\", defaultValue=\"catalog.schema\", label=\"catalog\")\n",
    "dbutils.widgets.text(name=\"schema\", defaultValue=\"agents\", label=\"schema\")\n",
    "dbutils.widgets.text(name=\"model\", defaultValue=\"memory_agent\", label=\"model\")\n",
    "dbutils.widgets.text(\n",
    "    name=\"DATABRICKS_CLIENT_ID\", defaultValue=\"\", label=\"DATABRICKS_CLIENT_ID\"\n",
    ")\n",
    "dbutils.widgets.text(\n",
    "    name=\"DATABRICKS_CLIENT_SECRET\", defaultValue=\"\", label=\"DATABRICKS_CLIENT_SECRET\"\n",
    ")\n",
    "dbutils.widgets.text(name=\"secret_scope\", defaultValue=\"dbdemos\", label=\"secret_scope\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c7a72f0-bc6e-489d-8ec3-f4d7ba4238aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog = dbutils.widgets.get(\"catalog\")\n",
    "schema = dbutils.widgets.get(\"schema\")\n",
    "model = dbutils.widgets.get(\"model\")\n",
    "# LLM_ENDPOINT = dbutils.widgets.get(\"foundation_model\")\n",
    "assert (\n",
    "    len(catalog) > 0 and len(schema) > 0 and len(model) > 0\n",
    "), \"Please provide a valid catalog, schema, and model name\"\n",
    "three_tiered_model_name = f\"{catalog}.{schema}.{model}\"\n",
    "print(f\"{three_tiered_model_name=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a036ef50-66ac-45ec-b678-64d4c3fb3a5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "w = WorkspaceClient()\n",
    "\n",
    "DATABRICKS_HOST = w.config.host\n",
    "\n",
    "secret_scope_name = dbutils.widgets.get(\"secret_scope\")\n",
    "\n",
    "# if needed create a secret scope\n",
    "if secret_scope_name != \"dbdemos\":\n",
    "    w.secrets.create_scope(scope=secret_scope_name)\n",
    "else:\n",
    "    print(f\"Using existing secret scope: {secret_scope_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "632ff6d6-902c-478e-8d6f-2c8e743b6d31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if dbutils.widgets.get(\"DATABRICKS_CLIENT_ID\") == \"\":\n",
    "    print(\"no DATABRICKS_CLIENT_ID is provided\")\n",
    "else:\n",
    "    w.secrets.put_secret(\n",
    "        scope=secret_scope_name,\n",
    "        key=\"DATABRICKS_CLIENT_ID\",\n",
    "        string_value=dbutils.widgets.get(\"DATABRICKS_CLIENT_ID\"),\n",
    "    )\n",
    "if dbutils.widgets.get(\"DATABRICKS_CLIENT_SECRET\") == \"\":\n",
    "    print(\"no DATABRICKS_CLIENT_ID is provided\")\n",
    "else:\n",
    "    w.secrets.put_secret(\n",
    "        scope=secret_scope_name,\n",
    "        key=\"DATABRICKS_CLIENT_SECRET\",\n",
    "        string_value=dbutils.widgets.get(\"DATABRICKS_CLIENT_SECRET\"),\n",
    "    )\n",
    "w.secrets.put_secret(\n",
    "    scope=secret_scope_name, key=\"DATABRICKS_HOST\", string_value=DATABRICKS_HOST\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea052166-1d1a-44c3-9408-07a16b1bd28e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.environ[\"DATABRICKS_CLIENT_ID\"] = dbutils.secrets.get(\n",
    "#     scope=secret_scope_name, key=\"DATABRICKS_CLIENT_ID\"\n",
    "# )\n",
    "# os.environ[\"DATABRICKS_CLIENT_SECRET\"] = dbutils.secrets.get(\n",
    "#     scope=secret_scope_name, key=\"DATABRICKS_CLIENT_SECRET\"\n",
    "# )\n",
    "\n",
    "# os.unsetenv(\"DATABRICKS_CLIENT_ID\")\n",
    "# os.unsetenv(\"DATABRICKS_CLIENT_SECRET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12bb5e31-3252-4dc6-92e9-7013f1e83d43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Lakebase Config\n",
    "- Enable Postgres native role login\n",
    "- Might need to wait a few min for pg roles to apply\n",
    "- Create new catalog with PostgreSQL Database: `databricks_postgres` schema off lakebase instance for querying purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a30d7a7-7e08-4f6f-9b88-ed6ff462ae72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "w.database.get_database_instance(name=\"bo-test-lakebase-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2caaac13-e6d5-4475-8ea9-b8cb3abd21ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "import psycopg2\n",
    "import os\n",
    "import psycopg\n",
    "from psycopg_pool import ConnectionPool\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "\n",
    "w = WorkspaceClient(\n",
    "    host=dbutils.secrets.get(scope=secret_scope_name, key=\"DATABRICKS_HOST\"),\n",
    "    client_id=dbutils.secrets.get(scope=secret_scope_name, key=\"DATABRICKS_CLIENT_ID\"),\n",
    "    client_secret=dbutils.secrets.get(\n",
    "        scope=secret_scope_name, key=\"DATABRICKS_CLIENT_SECRET\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "instance_name = \"bo-test-lakebase-3\"\n",
    "\n",
    "PGPASSWORD = w.database.generate_database_credential(\n",
    "    request_id=str(uuid.uuid4()), instance_names=[instance_name]\n",
    ")\n",
    "\n",
    "conn_user = \"bo.cheng%40databricks.com\"\n",
    "conn_host = (\n",
    "    \"instance-71597a8a-7e99-4c85-b29a-f751a73ecb85.database.cloud.databricks.com\"\n",
    ")\n",
    "conn_db_name = \"databricks_postgres\"\n",
    "conn_ssl_mode = \"require\"\n",
    "conn_port = \"5432\"\n",
    "conn_info = f\"postgresql://{conn_user}:{PGPASSWORD.token}@{conn_host}:{conn_port}/{conn_db_name}?sslmode={conn_ssl_mode}\"\n",
    "\n",
    "\n",
    "def db_password_provider() -> str:\n",
    "    \"\"\"\n",
    "    Ask Databricks to mint a fresh DB credential for this instance.\n",
    "    Called only when the pool needs a new physical connection.\n",
    "    \"\"\"\n",
    "    cred = w.database.generate_database_credential(\n",
    "        request_id=str(uuid.uuid4()),\n",
    "        instance_names=[instance_name],\n",
    "    )\n",
    "    return cred.token\n",
    "\n",
    "\n",
    "class CustomConnection(psycopg.Connection):\n",
    "    \"\"\"\n",
    "    A psycopg Connection subclass that injects a fresh password\n",
    "    *at connection time* (only when the pool creates a new connection).\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def connect(cls, conninfo=\"\", **kwargs):\n",
    "        # Append the new password to kwargs\n",
    "        kwargs[\"password\"] = db_password_provider()\n",
    "        # Call the superclass's connect method with updated kwargs\n",
    "        return super().connect(conninfo, **kwargs)\n",
    "\n",
    "\n",
    "pool = ConnectionPool(\n",
    "    conninfo=f\"dbname={conn_db_name} user={dbutils.secrets.get(scope=secret_scope_name, key='DATABRICKS_CLIENT_ID')} host={conn_host} port={conn_port} sslmode={conn_ssl_mode}\",\n",
    "    connection_class=CustomConnection,\n",
    "    min_size=1,\n",
    "    max_size=10,\n",
    "    open=True,\n",
    "    kwargs={\n",
    "        \"autocommit\": True,\n",
    "        \"keepalives\": 1,\n",
    "        \"keepalives_idle\": 30,\n",
    "        \"keepalives_interval\": 10,\n",
    "        \"keepalives_count\": 5,\n",
    "    },\n",
    ")\n",
    "\n",
    "# # Example: use the pool to initialize your checkpoint tables\n",
    "with pool.connection() as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"select 1\")\n",
    "\n",
    "    checkpointer = PostgresSaver(conn)\n",
    "    checkpointer.setup()\n",
    "    print(\"✅ Pool connected and checkpoint tables are ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a76ad6f-9bb9-4260-a660-cd1f0cfdc53c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile agent.py\n",
    "from typing import Any, Generator, Optional, Sequence, Union\n",
    "import mlflow\n",
    "from databricks_langchain import (\n",
    "    ChatDatabricks,\n",
    "    VectorSearchRetrieverTool,\n",
    "    DatabricksFunctionClient,\n",
    "    UCFunctionToolkit,\n",
    "    set_uc_function_client,\n",
    ")\n",
    "from langchain_core.language_models import LanguageModelLike\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langchain_core.tools import BaseTool\n",
    "from langgraph.graph import END, StateGraph, MessagesState, START\n",
    "from langgraph.graph.graph import CompiledGraph\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState, ChatAgentToolNode\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentChunk,\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "import os\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "import uuid\n",
    "from databricks.sdk import WorkspaceClient\n",
    "import urllib.parse\n",
    "from databricks_ai_bridge import ModelServingUserCredentials\n",
    "from psycopg_pool import ConnectionPool\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "client = DatabricksFunctionClient()\n",
    "set_uc_function_client(client)\n",
    "\n",
    "############################################\n",
    "# Define your LLM endpoint and system prompt\n",
    "############################################\n",
    "LLM_ENDPOINT_NAME = \"databricks-claude-3-7-sonnet\"\n",
    "# llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "\n",
    "###############################################################################\n",
    "## Define tools for your agent, enabling it to retrieve data or take actions\n",
    "## beyond text generation\n",
    "## To create and see usage examples of more tools, see\n",
    "## https://docs.databricks.com/generative-ai/agent-framework/agent-tool.html\n",
    "###############################################################################\n",
    "tools = []\n",
    "\n",
    "# You can use UDFs in Unity Catalog as agent tools\n",
    "uc_tool_names = [\n",
    "    \"bo_cheng_dnb_demos.agents.get_cyber_threat_info\",\n",
    "    \"bo_cheng_dnb_demos.agents.get_user_info\",\n",
    "]\n",
    "uc_toolkit = UCFunctionToolkit(function_names=uc_tool_names)\n",
    "tools.extend(uc_toolkit.tools)\n",
    "\n",
    "# # (Optional) Use Databricks vector search indexes as tools\n",
    "# # See https://docs.databricks.com/generative-ai/agent-framework/unstructured-retrieval-tools.html\n",
    "# # for details\n",
    "#\n",
    "# # TODO: Add vector search indexes as tools or delete this block\n",
    "# vector_search_index_tools = [\n",
    "#     VectorSearchRetrieverTool(\n",
    "#         index_name=\"bo_cheng_dnb_demos.agents.poc_customer_support_index\",\n",
    "#         num_results=3,\n",
    "#         tool_name=\"customer_support_retriever\",\n",
    "#         tool_description=\"Retrieves information about customer support responses\",\n",
    "#         query_type=\"ANN\",\n",
    "#     )\n",
    "# ]\n",
    "# tools.extend(vector_search_index_tools)\n",
    "\n",
    "#####################\n",
    "## Define agent logic\n",
    "#####################\n",
    "\n",
    "\n",
    "class LangGraphChatAgent(ChatAgent):\n",
    "    def __init__(self, config, tools):\n",
    "        self.config = config\n",
    "        # self.connstring = conn\n",
    "        self.conn_db_name = self.config[\"conn_db_name\"]\n",
    "        self.conn_ssl_mode = self.config[\"conn_ssl_mode\"]\n",
    "        self.conn_host = self.config[\"conn_host\"]\n",
    "        self.instance_name = self.config[\"instance_name\"]\n",
    "        self.tools = tools\n",
    "        self.model = ChatDatabricks(\n",
    "            endpoint=self.config.get(\"llm_model_serving_endpoint_name\"), temperature=0.1\n",
    "        ).bind_tools(self.tools)\n",
    "        self.system_prompt = self.config.get(\"llm_prompt_template\")\n",
    "        self.pool_min_size = int(os.getenv(\"DB_POOL_MIN_SIZE\", \"1\"))\n",
    "        self.pool_max_size = int(os.getenv(\"DB_POOL_MAX_SIZE\", \"10\"))\n",
    "        self.pool_timeout = float(os.getenv(\"DB_POOL_TIMEOUT\", \"30.0\"))\n",
    "\n",
    "    def _get_oauth_connection_string(self):\n",
    "        \"\"\"Get a fresh OAuth token and return connection string\"\"\"\n",
    "        # self.w = WorkspaceClient(credentials_strategy=ModelServingUserCredentials())\n",
    "        self.w = WorkspaceClient()\n",
    "        try:\n",
    "            sp = self.w.current_service_principal.me()\n",
    "            sp_username = sp.application_id\n",
    "        except Exception:\n",
    "            user = self.w.current_user.me()\n",
    "            sp_username = urllib.parse.quote_plus(\n",
    "                user.user_name\n",
    "            )  # we need to allow encoding for local testing of the agent to work since it will pass in username\n",
    "\n",
    "        pg_credential = self.w.database.generate_database_credential(\n",
    "            request_id=str(uuid.uuid4()), instance_names=[self.instance_name]\n",
    "        )\n",
    "\n",
    "        conn_string = f\"postgresql://{sp_username}:{pg_credential.token}@{self.conn_host}:5432/{self.conn_db_name}?sslmode={self.conn_ssl_mode}\"\n",
    "\n",
    "        return conn_string\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        try:\n",
    "            thread_id = custom_inputs.get(\"thread_id\")\n",
    "        except:\n",
    "            thread_id = str(uuid.uuid4())\n",
    "\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "        checkpoint_config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "        messages = []\n",
    "        if self.system_prompt:\n",
    "            preprocessor = RunnableLambda(\n",
    "                lambda state: [{\"role\": \"system\", \"content\": self.system_prompt}]\n",
    "                + state[\"messages\"]\n",
    "            )\n",
    "        else:\n",
    "            preprocessor = RunnableLambda(lambda state: state[\"messages\"])\n",
    "        self.model = self.model.bind_tools(self.tools)\n",
    "        model_runnable = preprocessor | self.model\n",
    "\n",
    "        # Get connection string to connect to lakebase postgres instance\n",
    "        conn_info = self._get_oauth_connection_string()\n",
    "\n",
    "        # Run the agent with the checkpointer\n",
    "        with ConnectionPool(\n",
    "            conninfo=conn_info,\n",
    "            min_size=self.pool_min_size,\n",
    "            max_size=self.pool_max_size,\n",
    "            timeout=self.pool_timeout,\n",
    "            # Configure connection settings\n",
    "            kwargs={\n",
    "                \"autocommit\": True,\n",
    "                \"keepalives\": 1,\n",
    "                \"keepalives_idle\": 30,\n",
    "                \"keepalives_interval\": 10,\n",
    "                \"keepalives_count\": 5,\n",
    "            },\n",
    "        ).connection() as conn:\n",
    "            checkpointer = PostgresSaver(conn)\n",
    "\n",
    "            def should_continue(state: ChatAgentState):\n",
    "                messages = state[\"messages\"]\n",
    "                last_message = messages[-1]\n",
    "                # If there are function calls, continue. else, end\n",
    "                if last_message.get(\"tool_calls\"):\n",
    "                    return \"continue\"\n",
    "                else:\n",
    "                    return \"end\"\n",
    "\n",
    "            def call_model(\n",
    "                state: ChatAgentState,\n",
    "                config: RunnableConfig,\n",
    "            ):\n",
    "                response = model_runnable.invoke(state, config)\n",
    "\n",
    "                return {\"messages\": [response]}\n",
    "\n",
    "            workflow = StateGraph(ChatAgentState)\n",
    "\n",
    "            workflow.add_node(\"agent\", RunnableLambda(call_model))\n",
    "            workflow.add_node(\"tools\", ChatAgentToolNode(self.tools))\n",
    "\n",
    "            workflow.set_entry_point(\"agent\")\n",
    "            workflow.add_conditional_edges(\n",
    "                \"agent\",\n",
    "                should_continue,\n",
    "                {\n",
    "                    \"continue\": \"tools\",\n",
    "                    \"end\": END,\n",
    "                },\n",
    "            )\n",
    "            workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "            graph = workflow.compile(checkpointer=checkpointer)\n",
    "            for event in graph.stream(\n",
    "                request, checkpoint_config, stream_mode=\"updates\"\n",
    "            ):\n",
    "                # print(event)\n",
    "                for node_data in event.values():\n",
    "                    messages.extend(\n",
    "                        ChatAgentMessage(**msg) for msg in node_data.get(\"messages\", [])\n",
    "                    )\n",
    "                # print(messages)\n",
    "            return ChatAgentResponse(messages=messages)\n",
    "\n",
    "\n",
    "# Create the agent object, and specify it as the agent object to use when\n",
    "# loading the agent back for inference via mlflow.models.set_model()\n",
    "\n",
    "config = {\n",
    "    \"llm_model_serving_endpoint_name\": \"databricks-claude-3-7-sonnet\",\n",
    "    \"llm_prompt_template\": \"\"\"\n",
    "    You are an cybersecurity assistant.\n",
    "    You are given a task and you must complete it.\n",
    "    Use the following routine to support the customer.\n",
    "    # Routine:\n",
    "    1. Provide the get_cyber_threat_info tool the type of threat being asked about.\n",
    "    2. Use the source ip address provided in step 1 as input for the get_user_info tool to retrieve user specific info.\n",
    "    Use the following tools to complete the task:\n",
    "    {tools}\"\"\",\n",
    "    \"conn_db_name\": \"databricks_postgres\",\n",
    "    \"conn_ssl_mode\": \"require\",\n",
    "    \"conn_host\": \"instance-71597a8a-7e99-4c85-b29a-f751a73ecb85.database.cloud.databricks.com\",\n",
    "    \"instance_name\": \"bo-test-lakebase-3\",\n",
    "}\n",
    "\n",
    "AGENT = LangGraphChatAgent(config=config, tools=tools)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36beb42b-d89b-4bde-adde-2509bcc03028",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from agent import AGENT\n",
    "\n",
    "AGENT.predict(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                # \"content\": \"My name is Bo\",\n",
    "                # \"content\": \"What is my name?\",\n",
    "                \"content\": \"Who committed the latest malware threat?\",\n",
    "            }\n",
    "        ],\n",
    "        \"custom_inputs\": {\"thread_id\": \"4\"},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37fef865-8ca5-4d0f-83a6-657b3edccf65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Determine Databricks resources to specify for automatic auth passthrough at deployment time\n",
    "import mlflow\n",
    "from databricks_langchain import VectorSearchRetrieverTool\n",
    "from mlflow.models.resources import (\n",
    "    DatabricksFunction,\n",
    "    DatabricksServingEndpoint,\n",
    "    DatabricksLakebase,\n",
    "    DatabricksVectorSearchIndex,\n",
    ")  # we are adding DatabricksLakebase resource type\n",
    "from mlflow.models.auth_policy import AuthPolicy, SystemAuthPolicy, UserAuthPolicy\n",
    "from unitycatalog.ai.langchain.toolkit import UnityCatalogTool\n",
    "from agent import LLM_ENDPOINT_NAME, tools\n",
    "\n",
    "# TODO: Manually include additional underlying resources if needed and update values for endpoint/lakebase\n",
    "resources = [\n",
    "    DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME),\n",
    "    DatabricksLakebase(database_instance_name=\"demo-lakebase-instance\"),\n",
    "    # DatabricksVectorSearchIndex(\n",
    "    #     index_name=\"catalog.schema.agents.poc_customer_support_index\"\n",
    "    # ),\n",
    "]\n",
    "for tool in tools:\n",
    "    if isinstance(tool, VectorSearchRetrieverTool):\n",
    "        resources.extend(tool.resources)\n",
    "    elif isinstance(tool, UnityCatalogTool):\n",
    "        resources.append(DatabricksFunction(function_name=tool.uc_function_name))\n",
    "\n",
    "# System policy: resources accessed with system credentials\n",
    "system_policy = SystemAuthPolicy(resources=resources)\n",
    "\n",
    "# User policy: API scopes for OBO access\n",
    "api_scopes = [\n",
    "    \"sql.statement-execution\",\n",
    "    \"mcp.genie\",\n",
    "    \"mcp.external\",\n",
    "    \"catalog.connections\",\n",
    "    \"mcp.vectorsearch\",\n",
    "    \"vectorsearch.vector-search-indexes\",\n",
    "    \"iam.current-user:read\",\n",
    "    \"sql.warehouses\",\n",
    "    \"dashboards.genie\",\n",
    "    \"serving.serving-endpoints\",\n",
    "    \"iam.access-control:read\",\n",
    "    \"apps.apps\",\n",
    "    \"mcp.functions\",\n",
    "    \"vectorsearch.vector-search-endpoints\",\n",
    "]\n",
    "user_policy = UserAuthPolicy(api_scopes=api_scopes)\n",
    "\n",
    "input_example = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What is an LLM agent?\"}],\n",
    "    \"custom_inputs\": {\"thread_id\": \"1\"},\n",
    "}\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"agent\",\n",
    "        python_model=\"agent.py\",\n",
    "        input_example=input_example,\n",
    "        extra_pip_requirements=[\n",
    "            \"databricks-connect\",\n",
    "            \"databricks-agents\",\n",
    "            \"databricks-langchain\",\n",
    "            \"unitycatalog-langchain[databricks]\",\n",
    "            \"psycopg[binary,pool]\",\n",
    "            \"langgraph-checkpoint-postgres==2.0.21\",\n",
    "            \"langgraph==0.3.4\",\n",
    "            \"langchain\",\n",
    "        ],\n",
    "        # auth_policy=AuthPolicy(\n",
    "        #     system_auth_policy=system_policy, user_auth_policy=user_policy\n",
    "        # ),\n",
    "        resources=resources,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a986456a-f881-46e3-99fe-99b0ef7758ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.models.predict(\n",
    "    model_uri=f\"runs:/{logged_agent_info.run_id}/agent\",\n",
    "    input_data=input_example,\n",
    "    env_manager=\"uv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc29adc0-2738-4fbb-8e0f-92e93bd50617",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# TODO: define the catalog, schema, and model name for your UC model\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model}\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri,\n",
    "    name=UC_MODEL_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9be4813e-2d48-4dff-b900-d9d7c9d2d013",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "\n",
    "agents.deploy(\n",
    "    UC_MODEL_NAME,\n",
    "    uc_registered_model_info.version,\n",
    "    environment_vars={\n",
    "        \"DATABRICKS_HOST\": \"{{secrets/dbdemos/DATABRICKS_HOST}}\",\n",
    "        \"DATABRICKS_CLIENT_ID\": \"{{secrets/dbdemos/DATABRICKS_CLIENT_ID}}\",\n",
    "        \"DATABRICKS_CLIENT_SECRET\": \"{{secrets/dbdemos/DATABRICKS_CLIENT_SECRET}}\",\n",
    "    },\n",
    "    tags={\"endpointSource\": \"playground\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d140d2fc-c5ce-42ad-b45d-a269de8b7507",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "\n",
    "# Note that  can specify individual users or groups.\n",
    "agents.set_permissions(\n",
    "    model_name=UC_MODEL_NAME,\n",
    "    users=[\"users\"],\n",
    "    permission_level=agents.PermissionLevel.CAN_QUERY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8af7987e-5dbe-4fa3-ae99-a7ca0f0578ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next steps\n",
    "After your agent is deployed, you can chat with it in AI playground to perform additional checks, share it with SMEs in your organization for feedback, or embed it in a production application. See docs for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65fc3451-8d75-47ff-82e0-ed29102f09ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from databricks.sdk.service.serving import EndpointStateReady, EndpointStateConfigUpdate\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "endpoint_name: str = f\"agents_{catalog}-{schema}-{model}\"\n",
    "print(\"\\nWaiting for endpoint to deploy.  This can take 10 - 20 minutes.\", end=\"\")\n",
    "w = WorkspaceClient()\n",
    "while (\n",
    "    w.serving_endpoints.get(endpoint_name).state.ready == EndpointStateReady.NOT_READY\n",
    "    or w.serving_endpoints.get(endpoint_name).state.config_update\n",
    "    == EndpointStateConfigUpdate.IN_PROGRESS\n",
    "):\n",
    "    print(\".\", end=\"\")\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bac4a02e-42c0-4479-a657-4c48ba3dc6aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "w = WorkspaceClient()\n",
    "endpoint_name: str = f\"agents_{catalog}-{schema}-{model}\"\n",
    "response = w.serving_endpoints.query(\n",
    "    name=endpoint_name,\n",
    "    dataframe_records=[\n",
    "        {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Who was just mentioned for a cybersecurity incident?\",\n",
    "                }\n",
    "            ],\n",
    "            \"custom_inputs\": {\"thread_id\": \"4\"},\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d6a6bb4-a944-40db-9726-5e09adf4fe82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2,
    "widgetLayout": []
   },
   "notebookName": "02-lakebase-langgraph-checkpointer-agent",
   "widgets": {
    "DATABRICKS_CLIENT_ID": {
     "currentValue": "",
     "nuid": "18a2b9fc-2a9d-4b4a-9745-a987f8273c27",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "DATABRICKS_CLIENT_ID",
      "name": "DATABRICKS_CLIENT_ID",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": "DATABRICKS_CLIENT_ID",
      "name": "DATABRICKS_CLIENT_ID",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "DATABRICKS_CLIENT_SECRET": {
     "currentValue": "",
     "nuid": "f336e7aa-427b-40a8-9abd-d4b99be576b8",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "DATABRICKS_CLIENT_SECRET",
      "name": "DATABRICKS_CLIENT_SECRET",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": "DATABRICKS_CLIENT_SECRET",
      "name": "DATABRICKS_CLIENT_SECRET",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "catalog": {
     "currentValue": "bo_cheng_dnb_demos",
     "nuid": "2b1943f2-92cd-4f7a-a824-a27ce3498e62",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "bo_cheng_dnb_demos",
      "label": "catalog",
      "name": "catalog",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "bo_cheng_dnb_demos",
      "label": "catalog",
      "name": "catalog",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "model": {
     "currentValue": "memory_agent",
     "nuid": "fe1c81e8-14a0-417e-ac97-d1e2dedace82",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "memory_agent",
      "label": "model",
      "name": "model",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "memory_agent",
      "label": "model",
      "name": "model",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "schema": {
     "currentValue": "agents",
     "nuid": "62018a9f-5147-4245-8c23-b83350be3cbb",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "agents",
      "label": "schema",
      "name": "schema",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "agents",
      "label": "schema",
      "name": "schema",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "secret_scope": {
     "currentValue": "dbdemos",
     "nuid": "a3917bf5-f120-4e11-82a8-fd1ea3803bd6",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "dbdemos",
      "label": "secret_scope",
      "name": "secret_scope",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "dbdemos",
      "label": "secret_scope",
      "name": "secret_scope",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
